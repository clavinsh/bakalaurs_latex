\documentclass[12pt]{report}% Šablona Kristiāns Kacars 2022. Last updated 08.02.2023

%\usepackage[utf8]{inputenc} neizmanto XeLatex, tad jāatkomentē.
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{
 a4paper,
 left=30mm,
 top=20mm,
 right=20mm,
 bottom=20mm,
 includehead
 }


\usepackage{xcolor}
\usepackage[]{graphicx}
\usepackage{setspace}
%\onehalfspacing %rindstarpas 1.5 vienības
\linespread{1.5}
\usepackage{placeins}%ērti izmantot \FloatBarrier, lai neļauti attēliem aiziet pārāk tālu no vajadzīgās vietas.
\usepackage{titlesec}%izveido atstarpes starp chapter un section nosaukumu
\usepackage{indentfirst}%pirmai rindkopai sekcijas sākumā nav atkāpe, ar šo tā tiek uzlikta
\titleformat{\chapter}
  {\normalfont\fontsize{16}{18}\bfseries\raggedright}{\thechapter.}{0pt}{\MakeUppercase}{}
  
\titleformat{\section}
  {\normalfont\fontsize{14}{16}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\fontsize{12}{16}\bfseries}{\thesubsection}{1em}{}  

\titlespacing*{\chapter}{0pt}{0pt}{10pt}
\titlespacing*{\section}{0pt}{5pt}{5pt}


\usepackage{fancyhdr}%šis izveido header, lai tur ir līnija ar section nosaukumu
\newcommand{\changefont}{%
    \fontsize{9}{11}\selectfont
}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[C]{\thepage}
\fancyhead[L]{\changefont \leftmark}

\usepackage{polyglossia}
\setdefaultlanguage{latvian}
\usepackage{lipsum}
\setlength{\parskip}{1.5pt}%atstarpe starp rindkopām

%matematikas paketes
\usepackage{amsmath} 
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{bm}%ērts priekš treknraksta matemātiskajā vidē
\usepackage{esint}%integrāļu zīmes, kas nav parastajās ams paketēs

%--pašizveidotās matemātikas komandas
\newcommand{\bra}{\langle}
\newcommand{\ket}{\rangle}
%--

\newtheorem{theorem}{Teorēma}
\theoremstyle{definition}
\newtheorem{definition}{Definīcija}

\usepackage{siunitx}%mērvienībām

%Algoritmu atspoguļošanai
\usepackage[ruled, vlined, linesnumbered, algochapter]{algorithm2e}
\renewcommand{\algorithmcfname}{Algoritms}% nomaina nosaukumu uz latviešu variantu
\usepackage[labelfont={bf}]{caption}%attēlu un tabulu nosaukumu fonts

\usepackage[style=phys,%der arī citi, piem., chem-angew(bibliogrāfijā pie article nav links)
articletitle=false,
biblabel=brackets,%
chaptertitle=false,%
    sorting=none,%kārto pēc citēšanas secības
    date=short]{biblatex}
\addbibresource{biblio.bib}


\usepackage{hyperref}%Izveido spiežamus linkus saturam, bibliogrāfijām uc.
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}


\newcommand*{\SavedEqref}{}%Dod krāsainus un spiežamus vienādojumu linkus
\let\SavedEqref\eqref
\renewcommand*{\eqref}[1]{%
  \begingroup
    \hypersetup{
      linkcolor=blue,
      linkbordercolor=black,
    }%
    \SavedEqref{#1}%
  \endgroup
}%vienādojumiem


\usepackage{chngcntr}%figure numeration
\counterwithin{figure}{chapter}
\counterwithin{table}{chapter}
\counterwithin{equation}{chapter}%vienadojumu numerācija veidojas pa nodaļām



%Pakete izveido apzīmējumu sarakstu
\usepackage{nomencl}
\makenomenclature
\renewcommand{\nomname}{Apzīmējumu saraksts}
%% Sadala grupās apzīmējumus
%Ja gribat pievienot papildu kategoriju, nokopējat-->
%   \ifstrequal{#1}{F}{Fizikas konstantes}{%
% tikai pēdējā rindiņā( kur ir Lielumu apzīmējumi) ieliekat papildu "}"
% -----------------------------------------
\usepackage{etoolbox}
\renewcommand\nomgroup[1]{%
  \item[\bfseries
  \ifstrequal{#1}{N}{}
]}

% pakete priekš koda formatēšanas
\usepackage{listings}
\renewcommand{\lstlistingname}{Izdruka}
\lstset{
  language=C++,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  stringstyle=\color{red},
  commentstyle=\color{green!50!black},
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  frame=single,
  tabsize=2,
  breaklines=true,
  showstringspaces=false,
  aboveskip=1mm, % Reduce space above the listing
  belowskip=1mm, % Reduce space below the listing
  lineskip=-1pt, % Adjust line spacing between lines
}

\usepackage{tabularx}




% --------------------------------------------
% ------- beidzas package izsaukšana un stila veidošana






%%%--------- Aizpildīt titullapu---------- 
%% Šis aizpildīs template titullapu ar jūsu informāciju
% Darba tips, i.e. bakalaura vai maģistra
\def\degree{Kursa darbs}
% Fakultātes nosaukums
\def\faculty{Eksakto zinātņu un tehnoloģiju fakultāte}
% Nodaļa iekš fakultātes
\def\department{Datorikas nodaļa}
% Universitātes nosaukums
\def\university{Latvijas Universitāte}
% Universitātes logo
\def\crest{\includegraphics[width = 0.5\textwidth]{LU_logo_LV_horiz.png}}%ja ieliekat attēlu kādā mapē, tad jāsauc attēls no šīs mapes, citādi neparādīsies tas titullapā.
\def\vietlaiks{Rīga, 2024}
\def\supervisor{Darba vadītājs: profesors, Dr. dat. Leo Seļāvo}
\def\studaplieciba{ak21373}
\author{Artūrs Kļaviņš}
\title{GPU programmēšanas salīdzinājums CUDA, ROCm un OpenCL saskarnēs}
\date{Maijs 2025}
\newcommand{\thedate}[0]{01.05.2025}%iesniegšanas datums
%%%---------- Beidz aizpildīt titullapu----------- 




\begin{document}



\thispagestyle{empty}
\makeatletter
   \begin{center}
       \vspace*{1cm}
        
    \vspace{10mm}
    {\Large LATVIJAS UNIVERSITĀTE\\
    \MakeUppercase{\faculty}\\
    \vspace{2mm}
    \MakeUppercase{\department}
    }
    \vspace*{10mm}
    
    
    
    \vspace{5mm}
    {\Large \MakeUppercase{\textbf{\@title}}}
    \vspace{5mm}
    

       \vspace{1cm}
    \Large
    \MakeUppercase{\degree}
    \end{center}
    \vspace{3cm}
    \begin{flushleft}
    \large
       Autors: \textbf{\large \@author}\\
       Studenta apliecības Nr.: \studaplieciba \\
       \supervisor
    \end{flushleft}

       \vfill
     
    \begin{center}
    \Large      
    \MakeUppercase{\vietlaiks}
   \end{center}
\makeatother

\newpage




\thispagestyle{empty}
\noindent \textbf{Anotācija}

\noindent Darbā gan teorētiski, gan praktiski tiks apskatītas CUDA, ROCm un OpenCL GPU
programmēšanas saskarnes. Tiks salīdzināta saskarņu dokumentācija, piedāvātās
programmatūras iespējas un ierobežojumi atbalstītajā aparatūrā. Praktiski tiks ieviesta
paroļu uzlaušanas un Džona Konveja dzīves spēles programmas katrā saskarnē,
apskatīti īstenošanas apsvērumi un analizēta ātrdarbība uz vienas un tās pašas
aparatūras.

\vspace{4mm}
\noindent \textbf{Atslēgas vārdi}: GPU, Nvidia, AMD, CUDA, ROCm, OpenCL

\vspace{20mm}
\noindent \textbf{Abstract}

\noindent Abstract body

\vspace{4mm}
\noindent \textbf{Keywords}: GPU, Nvidia, AMD, CUDA, ROCm

\newpage
\tableofcontents
\newpage

%Apzīmējumu saraksts

\nomenclature[N]{GPU}{Grafiskais procesors (no angļu val. \textit{Graphical Processing Unit})}
\nomenclature[N]{CPU}{Centrālais procesors (no angļu val. \textit{Central Processing Unit})}
\nomenclature[N]{CUDA}{\textit{Compute Unified Device Architecture} ir Nvidia ieviests API, kas ļauj
programmatūrai izmantot NVIDIA ražotos GPU}
\nomenclature[N]{GPGPU}{\textit{General-purpose computing on graphics processing units} - plašlietojama
skaitļošana uz grafiskajiem procesoriem, mūsdienās ņem vērā un ievieš procesora arhitektūras līmenī}
\nomenclature[N]{Ēnotājs}{Datorgrafikas programma, kura apstrādā tekstūru, 3D objektu un ainu gaismas
līmeņus un krāsas}
\nomenclature[N]{HPC}{Augstas veiktspējas skaitļošana (no angļu val. \textit{High-performance Computing})
ir datoru klāsteru izmantošana, lai ar lielu paralelitātes pakāpi risinātu kādu problēmu, apstrādātu milzīga
apjoma datus}
\nomenclature[N]{ROCm}{AMD izstrādātā atvērtā pirmkoda platforma priekš HPC un AI darbiem ar videokartēm}
\nomenclature[N]{HIP}{ROCm sastāvdaļa, C++ API programmu izstrādei uz AMD un Nvidia videokartēm
(no angļu val. \textit{Heterogeneous-computing Interface for Portability})}
\nomenclature[N]{AI}{Mākslīgais intelekts (no angļu val. \textit{Artifical Intelligence})}

% jaunie (iepriekšminētajiem derētu pārskatīt atbilstību)

\nomenclature[N]{Saimnieks}{}
\nomenclature[N]{Ierīce}{}






\printnomenclature

\chapter{Ievads}
Grafiskais procesors vai nu kā atsevisķa vai centrālajā procesorā integrēta komponente ir sastopama
gandrīz visos modernajos datoros. Vēsturiski izmantota tikai grafisko elementu
apstrādei, kur paralēli veicami daudzi līdzīgi darbi, piemēram, teksta renderēšana, pikseļu aizpildīšana uz
ekrāna, 3D ēnotāju funkcijas.

Kļuva skaidrs, ka GPU augstās paralelizācijas iespējas varētu izmantot citos uzdevumos,
kuri klasiski pildāmi uz CPU. Rezultātā tos būtu daudz efektīvāk pildīt uz GPU, palielinot programmu
ātrdarbību.

Pirms moderniem ietvariem, saskarnēm un arhitektūras atbalstu, ar kuru palīdzību uz GPU iespējams skaitļot
principā jebko, programmētājiem vajadzēja atrast 'nestandarta' risinājumus, lai pildītu ne-grafiskas problēmas.
Piemēram, 2003. gadā radās risinājums kā skaitļot vispārējus lineārās algebras vienādojumus,
pārveidojot matricu datus kā tekstūras un uz tām izpildot ēnotājus. \cite{10.1145/882262.882363}

Līdz ar to radās pieprasījums pēc plašlietojamas skaitļošanas uz grafiskajiem procesoriem. GPU ražotāji
to sāka ņemt vērā un 2006. gadā Nvidia ieviesa CUDA API platformu ar tiešu tās atbalstu uz Nvidia 
videokartēm, sākot ar "Tesla" GPU mikroarhitektūru.\cite{nvidia_tesla_p100}

Nvidia videokartes sākot jau no tā paša 2006. gada ir bijušas tirgus līderes, un tādas ir vēl joprojām.
AMD nepalīdzēja fakts, ka savu ROCm platformu ieviesa daudz vēlāk, tikai 2016. gadā, kā tieši konkurentu CUDA,
kad jau CUDA bija praktiski pierādīta un lietota 10 gadus.

Nvidia videokartes un CUDA dominē kā populārākā GPU izvēle un plašlietojuma GPU skaitļošanas (GPGPU)
platforma. No digitālās izplatīšanas platformas "Steam" 2024. gada decembra aparatūras un programmatūras
aptaujas var secināt, ka 75\% "Steam" lietotāju izmanto Nvidia videokartes, bet tikai 16\% - AMD.
\cite{steam_survey}

Bet ROCm programmatūras steks ar GPU programmēšanas, dziļās mašīnmācīšanās, HPC iespējām līdzinās
pieejamajās iespējās ar CUDA. Tāpēc šī darbā mērķis ir salīdzināt abas platformas, to pieejāmas salīdzināmās
funkcijas, ātrdarbību un iespējamās priekšrocības, izvēloties vienu vai otru.


\begin{center}
\chapter{Pieraksti par OpenCL}
\end{center}

Izskatās, ka ir diezgan zems apjoms ar modernām OpenCL 3.0 pamācībām, izņemot tehniskās
specifikācijas, kuras iesācējām varētu nebūtu piemērotas.

Jaunākā pamācības literatūra ir priekš opengl 2.0, iznāca 2015 gadā \cite{heterogeneous-computing-with-opencl-2-0}(debetable vai jaunākā, bet
zināmākā)

OpenCL nav beginner friendly, pārsvarā paredzēts izstrādātājiem, kuri jau labi spējīgi orientēti precīzi tehniskās specifikācijās,
lai rakstītu platform-neaktarīgas programmas priekš CPU, GPU u.c. hardware paātrinātājiem

Nvidia izskatās, ka ir OpenCL atbalsts

Izmanto SPIR starp-posma reprezentācijas (intermediate represenatation) valodu, kas izmantota arī citās Khronos Group
valodās, ietvaros - Vulkan, SYCL

Labi atsaukties uz specifikāciju \cite{opencl-spec}

Varbūt derētu realizēt benchmarkingu ar profilēšanas rīkiem, lai precizāk noskaidrot dažādās 'veiktspējas'
dažādos izpildes posmos, piemēram:
\begin{itemize}
    \item atmiņas iedalīšana uz gpu,
    \item vendor atrašana un iespējams kodola kompilēšana (opencl gadījumā ig)
    \item kodola izpilde,
    \item atmiņas atbrīvošana
\end{itemize}


Kādas varētu būt atšķirības programmēšanas modelī starp CUDA, HIP, OpenCL? Idejiski jau mērķa arhitektūra ir
apmēram vienāda, līdz ar to liekas, ka modelim ar tādam vajadzētu būt.

Kodola funkciju deklarācijā jāuzmanās no bool tipiem. Lai gan iekšēji OpenCl kodā ir atbalstīts bool tips,
šim tipam nav tieša attiecība API definīcijā, saskaroties ar samnieka puses kodu.
Plašāk skatoties, samnieka pusē ir, piemēram \textit{cl\_int} un OpenCL kodolā ir vienkārši \textit{int}.
Šāda it kā iebūvētop

\section{OpenCL platformas modelis - pieraksti pa taisno no dokumentācijas}
Sastāv no saimnieka (CPU) ar vienu vai vairākām OpenCL iekārtām (GPU).

OpenCL iekārta ir iedalīta vienā vai vairākās \textit{compute} vienībās (Compute Units), un tās ir iedalītas apstrādes elementos (processing elements)

Skaitļošana notiek šajos apstrādes elementos

OpenCL programma sastāv no saimnieka koda un iekārtas koda. 
Saimnieka koda daļa nodod kodola (kernel) kodu OpenCL iekārtai un iekārta to izpilda uz tās apstrādes elementiem.


Kad apstrādes elementi apstrādes vienībā izpilda to pašu secību ar priekšrakstiem (? varētu labāk izvārdod), tad vadības plūsma ir saucama par kopdarbīgu (converged)

Kopdarbīga vadības plūsma ir labi piemērota uz tādas aparatūrus kā GPU, kura ir specializēta vienas instrukciju kopas izpildei paralēli uz vairākiem apstrādes elementiem.
Nav grūti izsecināt, ka uz šādas aparatūras noteiktas OpenCL programmas izpildīs konkrētus uzdevumus ātrāk par līdzīgu risinājumu uz saimnieka - CPU.

Iekārtas kodola kodu ir iespējams sniegt kā OpenCL C99 pirmkoda simbolu virkni, SPIR-V starpvalodu vai bināru objektu.
OpenCL piedāvā kompilatoru, kas spējīgs no minētajiem formātiem izveidot izpildāmo programmas objektu.

Kompilators var būt 'tiešsaistes' vai 'bezsaistes' jeb
\begin{itemize}
    \item Tiešsaistes kompilators ir pieejams saimnieka programmas izpildes laikā
    \item Bezsaistes tiek izsaukts atsevišķi un saimnieka programmai tiek nodots un ielādēts gatavs SPIR-V izpildāms fails 
\end{itemize}

\textcolor{red}{Izskatās, ka salīdzinot ar HIP un CUDA, te ir lielāka brīvība veidos kā realizē kodola programmas kompilēšana un palaišanu, bet derētu paskatīties vairāk par šo tajās platformās}

Tiešsaistes kodolu kompilēšana nodrošina lielāku savietojamību ar dažādām aparatūrām, jo OpenCL kompilēs kodu tiešai attiecīgajai aparatūrai,
jo OpenCL nodrošina izpildes laika kompilēšanu visos gadījumos un API versijās.

Turpretī, gatavie SPIR-V binārie faili nav atbalstīti uz jebkuras aparatūras, kā arī ne visas OpenCL versijas ir savietojamas ar visām SPIR-V versijām.

Tomēr izpildes laika kodolu kompilēšana ir ar savu mīnusu - programmai jāvelta laiks kompilējot kodolus, ieviešot ātrdarbības zudumus. \textcolor{red}{te varētu novērtēt šos zudumus}

Ņemot vērā kā GPU arhitektūru apraksta Nvidia un AMD, šis OpenCL platformas modeļa abstrakcijas slānis ir raksturojams kā 'tuvu dzelžiem'.
Tomēr kodola kompilatoram ir diezgan brīva izvēle optimizācijās starp faktiskajiem arhitektūras elementiem un kā tos reprezentē OpenCL.

Piemērs, šim faktam ir situācijas, kur iekārtas kodola programma tiek kompilēta priekš CPU. Centrālais procesors arhitektūras līmenī var nesaturēt
vairākus kodolus vai pavedienus, kurus programmētājs sagaida izstrādājot iekārtas kodolu.

Vai arī, palaižot kodolu, tiek definēts pavedienu grupas izmērs (piemēram, izmērā 128), kas uz visām iekārtām nebūs pieejams tādā skaitā.
Kompilators šo situāciju atrisinātu, izsaucot kodolu vairākās partijās, bet no pirmkoda puses tiek definēta viena partija. 

Izskatās, ka daudz plašāks iebūveto tipu saraksts un atbalsts

\textcolor{red}{Te arī jāpārliecinās, bet man liekas, ka HIP un CUDA pie nederīga grupas/pavediena izmēra izmestu izpildes laika kļūdu, OpenCL dod lielāku brīvību}

Ne-primitīvu datu struktūru izveide un apstrāde:
Jāņem vērā, ka dinamiski mainīgas datu struktūras GPU kodā neiesaka lietot, kā arī OpenCL kontekstā, lietojamas tikai OpenCL standarta primitīvās datu struktūras,
tāpēc, papildus potenciāla problēma var būt ne-konsekventa atmiņas izlīdzināšana starp host, kodola kodu: \ref{lst:opencl_struct}

\begin{lstlisting}[caption={Piemērs struktūras definēšanai, kura lietojama OpenCL kodolā},
  label=lst:opencl_struct,
  captionpos=t
]
// Host kods
typedef struct __atribute__ ((packed)) _mana_struktura
{
    cl_int a;
    cl_int b;
    cl_int c;
} mana_struktura;


// Device kods
typedef struct __atribute__ ((packed)) _mana_struktura
{
    int a;
    int b;
    int c;
};

// Argumenta padosana no host
clSetKernelArg(kernel, 0, sizeof(mana_struktura), mana_struktura);
\end{lstlisting}

Tā kā OpenCL kodolu valoda ir balstīta uz C99 standarta, 




Atšķirībā no CUDA un HIP, OpenCL ir mazāka brīvība iekārtas un saimnieka
funkciju definēšanā, kur CUDA un HIP ir iespējams definēt kaut ko šādu (skatīt
izdruku \ref{lst:device_host_func}):
\begin{lstlisting}[caption={Piemērs struktūras definēšanai, kura lietojama OpenCL kodolā},
  label=lst:device_host_func,
  captionpos=t
]
// CUDA un HIP
__device__ __host__ myVersatileFunc();
\end{lstlisting}

OpenCL gadījumā šādu funkciju kā minimums vajadzētu izcelt atsevišķā C galvenes
failā, ar krietni lielākām pieejamās funkcionalitātes limitācijām, balstoties
uz to, ka šai funkcijai jāatbilst OpenCL C valodas standartam.

\include{tex_includes/platformu_salidzin}

\include{tex_includes/etalonuzdevumu_config}

\include{tex_includes/uzdevumi}

\include{tex_includes/rezultati_anal}

\begin{center}
    \chapter{Etalonuzdevuma rezultātu līdzvērtība}
\end{center}


\section{Uzticamu etalonuzdevumu izveide}

Lai nodrošinātu, ka etalonuzdevuma rezultāti ir uzticami, tiem jābūt
atkārtojamiem, kā minimums, uz tādas pašas aparatūras un programmatūras.
\cite{reliable-benchmarking}



Kā min viena publikācija \cite{reliable-benchmarking}, mērīt pilno programmas
izpildes laiku var nebūt pietiekoši, piemēram, ar time utilītu, it īpaši
vairākpavedienu scenārijos. Lai gan minētajā pētījumā etalonuzdevumu
sastādīšana apspriesta tīri CPU izpildes kontekstā, vairākpavedienu izpildi un
to ietekmi no I/O darbībām var attiecināt arī priekš GPU.

Kaut kāda programmas izpildes daļa norisināsies uz CPU, un, mērot laikus uz
dažādām aparatūrām (ar uzsvaru uz izteikti atšķirīgu I/O ātrdarbību), var iegūt
neuzticamus rezultātus, jo etalonuzdevuma fokuss nav uz ievades, izvades
ātrumu.

Bakalaura darba autora kursa darbā\cite{kursa-darbs} tika izmantota iepriekš
minētā neieteiktā metode (ar time utilītu mērīts kopējais laiks), bet ņemot
vērā, ka etalonuzdevums tika veikts tikai vienas aparatūras ietvaros, tad
varētu secināt, ka I/O ietekme uz uzticamiem mērījumiem bija minimāla.

Tomēr nevar garantēt, ka, izpildot programmu uz citas aparatūras, varētu iegūt
tādus datus, kas mainītu iegūtos gala secinājumus kursa darbā.

Lai no šādiem riskiem izvairītos, tiks mērīti konkrēti programmas notikumi,
piemēram, kodola kompilēšanas laiks, kodola izpildes laiks, kopējais pavadītais
laiks GPU pusē u.tml.


Līdzīgi nevar iegūt noderīgus mērījumus par atmiņas lietojumu, jo iedalītā atmiņa ne-triviālai programmai mainās laika gaitā.

Tāpēc, kvalitātam etalonuzdevuma uzstadījumam papildus jāsatur:
maksimāli atļautais atmiņas lietojums,
maksimālais programmas izpildes laiks,

Vēl viena prasība ir konsekvents kopējais sistēmas stāvoklis pirms un pēc programmas darbināšanas. Lai to visvieglāk nodrošinātu,
tiks izmantota izolēta OS līmeņa virtuāzijas vide uz Docker\cite{docker-docs-engine} platformas.

Sistēmas stāvokļa neatkarību no CPU un OS kešošanas mehānismiem pavisam atdalīt nav iespējams, tāpēc pirms konkrētas programmas laidienu kopas mērīšanas,
tiks veikts 'iesildošais' laidiens, kura rezultāti netiks ņemti vērā. Tādējādi, mazinot kešatmiņas trāpījumu vai ne-trāpījumu ietekmi uz mērījumiem.

Kopumā definēts šādu uzstādījums, galvenokārt, ņemot vērā izstrādes laikā pieejamo aparatūru:
\begin{itemize}
    \item 16GB RAM,
    \item 6GB VRAM,
    \item gpgpu kodola lokālais grupas izmērs - 256 elementi,
    \item programma darbojas izolētā vidē - Docker konteinerī,
    \item Docker saimnieka operētājsistēma neveic citus relatīvi resurs-intensīvus darbus
\end{itemize}

Priekš Nvidia CUDA un AMD HIP eksistē jau gatavi profilēšanas risinājumi, bet
OpenCL gadījumā nākas pašam apieties ar pieejamajām API funkcijām, līdz ar to
visām programmām jāsatur attiecīgie ekvivalentie GPU notikumu izsaukumi, kuri
tiek vienādi apstrādāti un žurnalēti programmas izpildes laikā. Piemēram, ar
platformu API funkcijām \textit{cudaEventRecord}, \textit{hipEventRecord},
\textit{clGetEventProfilingInfo}.


Datu struktūrām jābūt pietiekami ekvivalentām. To iespējams nodrošināt izmantojot, piemēram, ekvivalentus iebūvētos datu tipus.


Docker konteinera konfigurācija:
\begin{itemize}
    \item Atmiņas ierobežojums - 16GB,
    \item Atmiņas un \textit{swap} atmiņas ierobežojus - 16GB,
    \item Apstrādes failu piekļuvei no OS montēts sējums (angļu val. \textit{volume}) konteinera /data direktorijā
\end{itemize}


\begin{lstlisting}[caption={Docker konteinera palaišana un konfigurācija},
  label=lst:docker_konteinera_palaisanas piemers,
  captionpos=t
]
$ docker run --rm --gpus all -v ./data/:/data <konteinera nosaukums> /data/<apstradajamais fails> /data/<izvada fails> <citas opcijas>
\end{lstlisting}


Tā kā programmas notikumu ilgumi dažādās konfigurācijās nāks no CPU, CUDA, HIP un OpenCL pusēm, tad lai būtu
vienota un viegli apstrādājama datu kopa, notikumi tiks žurnalēti failā, izmantojot, spdlog\cite{spdlog-github}, C++ žurnalēšanas bibliotēku.

Ērtai datu apstrādei, izmantojamais faila formāts ir CSV, un datu formāts skatāms izdrukā \ref{lst:benchmark_log_example}.

\begin{lstlisting}[caption={Etalonuzdevuma žurnālfaila ieraksta formāts},
  label=lst:benchmark_log_example,
  captionpos=t
]
<Iekartas/platformas tips>,<Notikuma apraksts>,<Ilgums milisekundēs>
OpenCL, Kodola izpildes laiks, 38971
CUDA, Kodola izpildes laiks, 38971
HIP, Kodola izpildes laiks, 38971
\end{lstlisting}

Notikuma ilgums norādāms milisekundēs, jo, galvenokārt, tādā mērvienībā
notikumu ilgumu noklusēti atgriež gan CUDA, gan HIP profilēšanas funkcijas
\textit{cudaEventElapsedTime}, \textit{hipEventElapsedTime}. OpenCL funkcija
\textit{clGetEventProfilingInfo} atgriež notikuma ilgumu nanosekundēs, šajā
gadījumā rezultāti tiks pārveidoti, lai nodrošinātu konsekvenci starp pārējām
platformām.


\begin{center}
    \chapter{Uzdevumu definīcija un realizācija}
\end{center}

HIP risinājumiem par pamatu izmantots AMD ROCm izveidotais Docker fails \cite{hip-lib-docker}
kas definē gatavu izstrādes vidi tālākam darbam ar ROCm vai CUDA.



Situācijās kad kāda attiecīga OpenCL API funkcija nepiedāvā profilēšanas informāciju, CPU pusē funkcijas izpildes laiks mērāms ar chrono - steady clock 
Šādās situācijās arī CUDA un ROCm attiecīgās funkcijas izpildes laiks mērāms šādi, pat ja pieejama profilēšanas informācija, kas būtu precīzāka.
Šādi darīts, lai lieku ietekmi uz rezultātiem neradītu chrono virsdarbe vai profilēšanas virsdarbe.

GPGPU arhitektūra un programmēšana
\begin{center}
\chapter{GPGPU arhitektūra un programmēšana}
\end{center}

Procesi, kas izmanto GPU resursus, tipiski iedala atmiņu un sagatavo datus uz CPU, un tad nodod darbu
grafiskajam procesoram. Atmiņas iedalīšanas varianti ir stipri atkarīgi no veicamā uzdevuma un, būtiskāk, no
pieejamā GPU arhitektūras.

Vecākās videokartēs atmiņas iedalīšanu strikti veica CPU un to atmiņas ir pavisam atdalītas 
(RAM un VRAM - Video RAM). Modernāki risinājumi spējīgi pielietot vienotu
atmiņas apgabalu (CPU un GPU abi var piekļūt viens otra atmiņai), piemēram, Nvidia kartes sākot ar Pascal
mikroarhitektūru \cite{nvidia_tesla_p100}. Rezultātā programmētājam nav jāpārvalda,
kuras adreses ir centrālā un kuras grafiskā procesora. Vēl arī jāapsver, vai ir iespēja pa tiešo no GPU
iedalīt atmiņu, vai to darīs tikai CPU.

Protams, noteiktus abstrakcijas slāņus zemāk, procesoru atmiņas tomēr dzīvo dažādās vietās un nav apvienojami,
izņemot procesorus, kuros CPU un GPU dzīvo vienā čipā (integrētās videokartes).

Uz GPU izpildāmā programma tiek saukta par kodolu (no angļu val. \textit{kernel}), un no CPU ar draiveru
palīdzību tiek nodots:
\begin{itemize}
    \item uz GPU pavedieniem izpildāmais kodols,
    \item pavedienu skaits,
    \item kodola funkcijas argumenti (visbiežāk tās būs apstrādājamo datu atmiņas adreses - rādītāji).
\end{itemize}

Jāpārveido, lai nav grāmatas tulkojums:    GPU sastāv no daudziem kodoliem un katrs kodols izpilda
SIMT (\textit{Single instruction, multiple threads}) modelim atbilstošu iedoto izpildāmo kodolu




Derētu tad minēt šādas lietas
\begin{itemize}
   \item Augsta darbu paralelizācija lielo kodolu skaitu dēļ
   \item Īpašas instrukcijas konkrētu datu apstrādei
   \item Darbus nodod procesors (kaut kā īsti nezinu kā) GPU un GPU izmet atpakaļ rezultātu vai prasīto uzzīmē uz ekrāna
   \item Darbus var nodot GPU caur saskarnēm kā Nvidia CUDA vai AMD ROCm
\end{itemize}

SIMT kodoli - single instruction, multiple threads. Sadalās SIMT frontendā un SIMD (multiple data) backendā

SIMT steks, lai atbilstītu zarošanos

SIMT deadlock - paveidiens gaida uz atomicCAS, tālāk neies kamēr neizpildīs (while (!atomicCAS) ...), kad to dara vairāki paveidieni, tad var notikt deadlock

\begin{center}
\chapter{Platformu salīdzinājums}
\end{center}
Lai piesaistītu GPU programmētājus, AMD jau no sākuma dizainēja ROCm, lai tā līdzinātos CUDA. Protams,
abas platformas ir paradzētas GPU programmēšanai un apakšējā videokaršu arhitektūra nebūs tik atšķirīga.
Galvenā atšķirība, neskaitot platformu mērķa grafiskos procesorus, ir fakts, ka atšķirībā no CUDA, kura
ir slēgtā, ROCm ir atklātā pirmkoda programmatūra, līdz ar to, ja nepieciešams, visu programmatūras saturu 
var izpētīt, modificiēt, kompilēt pats, kā arī dot savu pienesumu gan dokumentācijā, gan kodā.\cite{what_is_ROCM}

ROCm dokumentācija ir ar savām problēmām, piemēram, lai atrastu instalāciju nākas diezgan dziļi meklēt
un 'lēkāt' starp lapām, lai atrastu konkrēto instalācijas failu. Instalācijas pamācības un lejupielādes
lapas ir diezgan sadalītas. CUDA šis process ir vienkāršāks, kā arī CUDA ir pastāvējusi daudz ilgāku
laiku, līdz ar to pieejamā literatūra, forumu diskusiju skaits ārpus oficiālajām dokumentācijām ir daudz 
lielāks nekā priekš ROCm.

ROCm satur vairākas programmas, bibliotēkas un ietvarus dažādiem darbiem ar augstas veiktspējas,
paralelizācijas skaitļošanu, bet konkrētais C++ API priekš GPU programēšanas ir HIP (no angļu val.
\textit{Heterogeneous-computing Interface for Portability}).\cite{HIP_docs}

Noteiktas HIP dizaina izvēles ir tieši aizņemtas no CUDA, lai CUDA vidē pieredzējušajiem
izstrādātājiem pāriet uz ROCm būtu vieglāk. Piemēram, C++ dekoratori, kuri norāda vai funkcija ir CPU
vai GPU, vai GPU kodola funkcija ir vienādi (skatīt  izdruku \ref{lst:cuda_hip_fn_decorators}).

\begin{lstlisting}[caption={CUDA un HIP funkciju definīciju salīdzinājums},
  label=lst:cuda_hip_fn_decorators,
  captionpos=t
]
// CUDA:
__host__ myCpuFunction() {/*...*/}
__device__ myGpuFunction() {/*...*/}
__global__ kernel() {}

// HIP:
__host__ myCpuFunction() {/*...*/}
__device__ myGpuFunction() {/*...*/}
__global__ kernel() {/*...*/}
\end{lstlisting}

HIP ir diezgan liels atbalsts ne tikai AMD videokartēm, bet arī Nvidia. Tas iespējams tāpēc, ka 
daudzas HIP saskarnes ir CUDA savietojamas, piemēram, GPU matemātisko funckiju API, tās saturošās funkcijas
ir tieši atbilstošas CUDA funkcijām.\cite{HIP_math_API,CUDA_math_API}

Kompilēšanas līmenī šis atbalsts ir iespējams, jo HIP izmanto kompilatoru draiveri 'hipcc', kurš,
atkarībā no platformas, veiks pirms-apstrādi un izsauks attiecīgo kompilatoru -
AMD videokartes gadījumā 'amdclang++' un Nvidia CUDA - 'nvcc'. \cite{HIP_compilers}.

Tā kā varētu interpretēt, ka CUDA ir tieša apakškopa ROCM un HIP platformai, bet tomēr pilnīgs atbalsts
visām CUDA funkcijām nav pieejams.



Tā kā, rakstot CUDA kodu, arī tiek izmantots tas pats 'nvcc' kompilators, ROCm piedāvā utilītu
pirmkoda migrēšanai - 'HIPIFY'. \cite{HIPIFY_github}

Potenciāls mīnuss HIP saistītām utilītām un bibliotēkam ir fakts, ka vairākām nav pieejama
"\textit{out of the box}" instalācija. Ir nepieciešamība kompilēt pirmkodu pašam, šo papildus soli
sarežģī atkarīgo pakešu pārvaldīšana. Windows gadījumā arī rodas sarežģījumi, jo ROCm utilītu noklusētā vide
ir Linux un visa ROCm izmantotais kompilators ir Clang/LLVM, kam uz Windows ir nepieciešama papildus 
konfigurēšana.
Piemērs šādai utilītai ir "HIPIFY", ar kuru iespējams pārveidot CUDA pirmkodu uz HIP. \cite{HIPIFY_github}

Tā kā CUDA ir slēgtā pirmkoda, tad, protams, visa programmatūra un rīki pieejami caur instalācijām un
rezultātā šis process ir daudz vienkāršāks.

Lai gan HIP atbalsta ir diezgan liels ierobežojums atbalstītajām videokartēm




ROCm paradzētā vide ir Linux, bet CUDA tā ir Windows. ROCm dokumentācijā, kur nepieciešams darbs ar komandrindas rīkiem, pamācības ir tikai Linux operētājsistēmai. CUDA gadījumā problēmas rodas jau instalācījas brīdī darbā ar Linux, jo nepieciešamas papildus darbības, konfigurācijas atkarībā no distributīva, izmantotā pakotņu pārvaldnieka sistēmas.

Atšķirībā no AMD, CUDA neizplata informāciju par savām videokartēm un tā kā Linux pats par sevi ir atklātā
pirmkoda programmatūra, tā nenāk ar Nvidia draiveriem. Tomēr projekts nouveau ar reversēs inženierijas
metodēm cenšas piedāvāt atklātā pirmkoda draiverus nvidia videokartēm
% https://en.wikipedia.org/wiki/Nouveau_(software)

Bet, lai izmantotu CUDA šis risinājums neder, jebkurā gadījumā nāksies overridot visus ne-Nvidia izlaistus draiverus. Linus |TOrvalds par arī ir izteicies, ka nosoda šādu kompānijas politiku.


% https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html



ROCm nav iekļauts populārākajās pakotņu pārvaldnieku sistēmās, lai gan ar automātisko instalāciju 
tiek iekļauts visa nepieciešamā programatūrā darbam ar ROCm programmām, problēmas rodas saskarnē ar
CUDA, jo nākas atrisināt atkarību problēmas. Noklusēti tiks meklēta cuda atkarība distributīva izmantotajā
pārvaldniekā, piemēram, Ubuntu "apt". Bet, šī atkarība satur tikai CUDA draiverus, nevis 
izstrādes rīkus, lai veiktu darbu ar CUDA Toolkit. 

Līdz ar to ir manuāli jāatrisina neatbilstošas pakotņu atkarības.


% https://github.com/ROCm/HIP/issues/820 - kā atrisināt cuda dependency




Kopumā AMD mērķis ar ROCm, atbalstot konkurent-kompāniju, ir sniegt gala lietotājiem, izstrādātājiem
vieglāku pārēju uz AMD platformu un videokartēm. Uzturot funkcionalitāti platform-neatkarīgu un
programmatūru rakstot HIP platformā, izstrādātāji ir spējīgi atbalstīt abu platformu videokartes.

Rezultātā kompānijas un gala lietotāji, sastādot datoru, serveru specifikāciju, varētu neuztraukties
par platform-atkarību, jo uzņēmumam svarīgā programmatūra, piemēram, mašīnmācīšanās bibliotēkas
strādātu bez problēmām gan uz Nvidia, gan AMD videokartēm.

AMD gadījumā, protams, ka labāka situācija būtu, ka tiktu izvēlēta viņu ražota videokarte. Un šādā teorētiskā
scenārijā tāds arī būtu iznākums, jo aptuveni vienādas specifikācijas videokartes starp abiem ražotājiem
ir ar lielu cenas starpību.

TABULA AR SPECIEM UN CENU


Bet, tā kā CUDA parādījās pirmā, kļuva par industrijas standartu un agrāk citu risinājumu nebija, 
mūsdienās plaši lietota programmatūra ir rakstīta uz CUDA. Piemēram, mašīnmācīšanās bibliotēka TensorFlow. \cite{tensorflow_github}

Migrēšana lielos projektos tomēr nav tik vienkāršs process, un ar šobrīdējo lielo AI pieprasījumu 


\chapter{Uzdevums}

Praktiskai platformu salīdzināšanai tomēr būtu nepieciešama videokarte.
Darba izstrādes laikā bija pieejams portatīvais dators ar:
\begin{itemize}
  \item AMD Ryzen 5600H procesoru ar Radeon Graphics integrēto videokarti
  \item Nvidia GeForce RTX 3060 Laptop ārējo videokarti
\end{itemize}

Lai gan it kā viena datora ietvaros būtu pieejamas gan Nvidia, gan AMD videokartes, diemžēl
integrētajai Radeon Graphics kartei nav ROCm atbalsts, kā arī HIP nav oficiāls atbalsts 
Nvidia videokārtēm uz Windows, tikai Linux. \textcolor{red}{Tāpēc par pamata platformu analīzē tiks izmantota CUDA.}

Iespējams risinājums ir WSL - \textit{Windows Subsystem for Linux}, ar kuru iespējams izmantot
Linux paredzētās programmas uz Windows. Gan CUDA, gan ROCm ir atbalsts un pamācības kā sakonfigurēt 
šīs platformas darbam uz WSL.\cite{nvidia_wsl_guide,rocm_wsl_guide}







Bet ņemot vērā, ka HIP atbalsta arī CUDA, būs iespējams apskatīt HIP iespējas uz Nvidia videokartes.

Jāizvēlas tāds uzdevums, kuru iespējams 'augsti' paralelizēt, tas ir, sadalīt uzdevumu daudzos mazos gabalos (vēlams skaitā >= 1 miljons),
lai būtu pievienotā vērtība (ātrdarbība) to pildīt uz GPU, ņemot vērā papildus darbu un nepieciešamās zināšanas, lai ieviestu GPU risinājumu.

Relatīvi vienkāršs, bet pietiekams uzdevums, lai parādītu ietvaru atšķirības un vispārīgi atšķirīgās
paradigmas starp CPU un GPU programmēšanu būtu paroļu lauzējs.

Nobriedušāki paroļi lauzēji, jeb precīzāk - paroļu atkopēji kā HashCat ir spējīgi ņemt vērā vairākas paroļu
variācijas, maskas, faktus, ka parole, piemēram, iesākusies ar "123" un citas sarežģītākas potenciālo paroļu
iegūšanas metodes. Demonstrācijas vajadzībām pietiktu izstrādāt pašu 'kodolu', kas, ar jau saņemtu
iespējamo paroļu sarakstu, tās pārbaudīs.


Tātad jāizstrādā programma, kas ņemot vērā ieejas failu ar potenciālajām parolēm, no kādas paroles
jaucējvērtības spētu noskaidrot 'hešoto' paroli.
Uzdevumu būtu vērts risināt uz GPU, jo pie liela paroļu skaita, katrs GPU kodols varētu rēķināt savas
paroles jaucējvērtību un pārbaudīt to pret uzlaužamo.

\section{Izstrādājamās programmas definīcija}
Programma ir domāta kā komandrindas utilīta ar CLI argumentiem:
\begin{itemize}
  \item testu palaišanais arguments
  \item ievades faila ceļš,
  \item paroles jaucējvērtība.
\end{itemize}

Apstrādājamais fails saturēs potenciālās paroles, katra savā rindā, kurām tiks izrēķināta jaucējvērtība un
salīdzināta pret doto. Izmantojamais jaukšanas algoritms - SHA256. Jaucējvērtību rēķināšana un salīdzināšana
jārealizē izpildei uz GPU.

SHA256 izvēlēts tā tīri tā popularitātes un relatīvi ātrās izpildes dēļ, paroles uzlaušanas demonstrācijas
vajadzībām ar šo pietiek, nepieciešamības gadījumā iespējams ieviest citu jaukšanas algoritmu un aizstāt
ar esošo.


Programmu iespējams palaist ar:
\begin{itemize}
  \item \texttt{\$ pwCracker --test}, lai vispārīgi pārbaudītu programmas darbību pret zināmām jaucējvērtībām
  un to attiecīgajiem ziņojumiem, kā arī, lai pārbaudītu GPU kodola programmas darbību, platformas
  pieejamību uz šī datora apartūras
  \item \texttt{\$ pwCracker <paroļu faila ceļs> <paroles hash vērtība>}, lai veiktu galveno programmas izpildi
\end{itemize}


\subsection{CUDA risinājums}

Lai gan CUDA ir domāta izstrādei uz C++, izpildāmais kods uz GPU ir ar saviem ierobežojumiem, kas neļauj pielietot C++ standarta bibliotēkas funkcijas, jo tās iekš 'CUDA device code' nav implementētas.
Vai nu tāpēc, ka kāda konkrēta funkcija ir visparīgi reti lietota, vai tā nav īsti paredzēta lietošanai iekš GPU.

Piemēram, nav pieejamas std::string, std::vector struktūras, jo tās dinamiski iedala atmiņu, kas darbībā iekš CUDA kerneļa būtu ļoti lēna darbība.
Tā kā paroles par nelaimi ir simbolu virknes, tad tās nāksies apstrādāt C stilā (char*), vai arī kā baitu masīvus (uint8\_t*).

Izstrādē ir jāvelta arī palielināta uzmanība datu struktūrām, to izvietojumam atmiņā, piemēram,
problēma kā glabāt pārbaudāmo paroļu sarakstu. Naivais risinājums būtu masīvs ar adresēm, kuras norāda uz pirmo simbolu konkrētās paroles simbolu virknē.

Problēma šajā risinājumā ir, ka netiek nodrošināta atmiņas blakusnodalīšana, tas ir, vienā nepārtrauktā atmiņas
apgabalā, jo konkrētā parole var teorētiski atrasties jebkur, paroles savstarpēji nav obligāti viena otrai
blakus. Līdz ar to varētu rasties lēndarbība no konkrētā pavediena izpildes kodolā - katrs pavediens savu
paroli meklētu teorētiski patvaļīgā vietā, kas var radīt kešatmiņas netrāpījumus.


Arī datu kopēšanas uz GPU atmiņu būs lēna, nāksies izmantot vairākas cudaMemcpy instrukcijas, katrai parolei.

Labāks risinājums ir izmantot nepārtrauktu paroļu buferi un katrai parolei fiksēt garumu, tām liekot galā 
nuļļu papildinājumus.


Jāņem vērā arī definētie kerneļa bloku un pavedienu skaiti ..

A reasonable minimum target is to launch a total number of threads of at least of SM * 2048.

https://forums.developer.nvidia.com/t/cuda-sha256-calculations-improvements/56757/4

These should be split between blocks with usually something in the range of 128,256, or 512 threads per block. It might be that 1024 threads per block is “OK”, it just requires some analysis to confirm.

Your GTX970 has 13 SMs, so target 13*2048 = 26K threads, ballpark, minimum. If you put 1024 threads per block, that would be 26 blocks. I’m not saying I know how to transform your code from 4 blocks to 26, but that is a reasonable performance goal, to maximize throughput.

\begin{lstlisting}
__global__ void kernel(
    const cuda::std::uint8_t *passwords,
    const int *pwLengths,
    int pwCount,
    cuda::std::uint64_t maxPwLength,
    const cuda::std::uint8_t *targetHash,
    int *resultIndex
)
{
    int idx = blockIdx.x * blockDim.x +threadIdx.x;

    if(idx >= pwCount)
    {
        return;
    }

    const cuda::std::uint8_t *password = passwords + (idx * maxPwLength);
    int pwLength = pwLengths[idx];

    cuda::std::uint8_t hash[32];


    sha256(password, pwLength, hash);

    // ja hashi sakrīt, tad ierakstām paroles indeksu iekš 'resultIndex',
    // tā kā tā mainīgā adrese atrodas device kopīgajā atmiņā, jālieto atomiska funkcija
    if(compareHashes(targetHash, hash))
    {
        // ja resultIndex glabājas vērtība -1, tad aizstāj to ar idx
        // ar šo tiek arī reizē nodrošināts, ka ja kāds pavediens vēlāk tomēr nonāk līdz šim stāvoklim,
        // tad modifikācija netiks veikta, jo tajā brīdī jau 'resultIndex' != -1
        atomicCAS((unsigned int*)resultIndex, -1, (unsigned int)idx);
    }
}
\end{lstlisting}


\texttt{nvcc -O2 kernel.cu -o main.exe}

\subsection{Portēšana uz HIP caur WSL 2}

\subsection{Analīze un secinājumi}

Ir jāpievērš uzmanība mērķa videokartei un mikroarhitektūrai, jo izstrādājot programmu uz personīgā datora 
ar RTX 3060 videokarti bija pieejamas funkijas, kuras testējot uz cita datora ar Quattro sērījas videokarti,
programma nestrādāja.

Ir situācijas, kad šo problēmu var atrisināt, kompilācijas brīdī definējot mērķa arhitektūras, bet,
ja izmantota kāda konkrēta funkcionalitāte, kura vienkārši nav pieejama uz mērķa, programma nestrādās.


Veiktspējas metrikas

\textbf{Vēl ir jāņem vērā virsdarbe, kopējot datus no iekārtas uz CPU un atpakaļ, šāda darbība ir relatīvi dārga}

\chapter{Platformneatkarīgi risinājumi}
ZLUDA, OpenCL


\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliogrāfija}
\printbibliography

\newpage
\chapter*{Pielikumi}
\addcontentsline{toc}{chapter}{Pielikumi}


Ja darbam nepieciešams, dažādus palīgmateriālus var ievietot pielikumā. Tajā
parasti iekļauj aprēķinu starprezultātus, ilustrācijas, anketu paraugus, kartes, aparātu un ierīču aprakstus u. c.


%dokumentācijas lapa
% autoram/ei izskatīt, nomainīt locījumu vārdiem
\newpage
\thispagestyle{empty}
\makeatletter
{\setstretch{2.0}
\noindent
\degree \ "\@title" izstrādāts LU Datorikas fakultātē.
\newline
\newline
\noindent
Ar savu parakstu apliecinu, ka pētījums veikts patstāvīgi, izmantoti tikai tajā norādītie informācijas avoti.
\newline
\newline
\noindent
Autors: \@author \space \rule{30mm}{0.2mm}
\newline
\newline
\newline
\noindent
Rekomendēju/nerekomendēju darbu aizstāvēšanai (nevajadzīgo izsvītrot)
\newline
\newline
\noindent 
\supervisor \space \rule{30mm}{0.2mm}
\newline
\newline
\newline
\newline
\newline
\noindent 
Darbs iesniegts Datorikas fakultātē
\newline
\newline
\noindent 
Dekāna pilnvarotā persona:
\newline
\newline
\newline
\newline
\noindent 
Darbs aizstāvēts kursa darbu komisijas sēdē
\newline
\newline
\newline
\newline
\newline
\noindent 
Komisija:
}
\makeatother

\end{document}
